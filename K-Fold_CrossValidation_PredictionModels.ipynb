{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program is for geenerating performance metrices (accuracy, precision, recall, f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model_evaluation_utils as meu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load and merge datasets # white = control; red = stroke; wine = data\n",
    "No_Concussion = pd.read_csv('Helathy Participants Data.csv', delim_whitespace=False)\n",
    "Yes_Concussion = pd.read_csv('Injured Participant Data.csv', delim_whitespace=False)\n",
    "\n",
    "# store wine type as an attribute\n",
    "No_Concussion['data_type'] = 'NoConcussion'   \n",
    "Yes_Concussion['data_type'] = 'Concussion'\n",
    "\n",
    "# merge control and stroke data\n",
    "datas = pd.concat([No_Concussion, Yes_Concussion])\n",
    "#datas = datas.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Prepare Training and Testing Datasets\n",
    "stp_features = datas.iloc[:,:-1]\n",
    "stp_feature_names = stp_features.columns\n",
    "stp_class_labels = np.array(datas['data_type'])\n",
    "\n",
    "X_data = datas.iloc[:,:-1]\n",
    "y_label = datas.iloc[:,-1]\n",
    "\n",
    "# Data Normalization\n",
    "ss = StandardScaler().fit(X_data)\n",
    "X = ss.transform(X_data)\n",
    "le = LabelEncoder()\n",
    "le.fit(y_label)\n",
    "y = le.transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for CV, KFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create model\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "results_lr = cross_validate(estimator=model_lr,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_lr)\n",
    "\n",
    "print('Logistic Regression Metrics:')\n",
    "print('Fit time:',results_lr['fit_time'])\n",
    "print('Score time:',results_lr['score_time'])\n",
    "print('10-fold Accuracy:',results_lr['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_lr['test_accuracy']),np.std(results_lr['test_accuracy'])))\n",
    "print('10-fold Precision:',results_lr['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_lr['test_precision']),np.std(results_lr['test_precision'])))\n",
    "print('10-fold Recall:',results_lr['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_lr['test_recall']),np.std(results_lr['test_recall'])))\n",
    "print('10-fold f1-score:',results_lr['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_lr['test_f1_score']),np.std(results_lr['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#train model\n",
    "model_dt = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "results_dt = cross_validate(estimator=model_dt,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_dt)\n",
    "\n",
    "print('Decision Tree Metrics:')\n",
    "print('Fit time:',results_dt['fit_time'])\n",
    "print('Score time:',results_dt['score_time'])\n",
    "print('10-fold Accuracy:',results_dt['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_dt['test_accuracy']),np.std(results_dt['test_accuracy'])))\n",
    "print('10-fold Precision:',results_dt['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dt['test_precision']),np.std(results_dt['test_precision'])))\n",
    "print('10-fold Recall:',results_dt['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dt['test_recall']),np.std(results_dt['test_recall'])))\n",
    "print('10-fold f1-score:',results_dt['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dt['test_f1_score']),np.std(results_dt['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "model_rf=RandomForestClassifier(n_estimators=50) \n",
    "\n",
    "results_rf = cross_validate(estimator=model_rf,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_rf)\n",
    "\n",
    "print('Random Forest Metrics:')\n",
    "print('Fit time:',results_rf['fit_time'])\n",
    "print('Score time:',results_rf['score_time'])\n",
    "print('10-fold Accuracy:',results_rf['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_rf['test_accuracy']),np.std(results_rf['test_accuracy'])))\n",
    "print('10-fold Precision:',results_rf['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rf['test_precision']),np.std(results_rf['test_precision'])))\n",
    "print('10-fold Recall:',results_rf['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rf['test_recall']),np.std(results_rf['test_recall'])))\n",
    "print('10-fold f1-score:',results_rf['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rf['test_f1_score']),np.std(results_rf['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Random Forest Hyperparameter Tuning\n",
    "model_rft = RandomForestClassifier(n_estimators=200, max_features='auto')\n",
    "\n",
    "results_rft = cross_validate(estimator=model_rft,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_rft)\n",
    "\n",
    "print('Random Forest with Hyperparameter Tuning Metrics:')\n",
    "print('Fit time:',results_rft['fit_time'])\n",
    "print('Score time:',results_rft['score_time'])\n",
    "print('10-fold Accuracy:',results_rft['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_rft['test_accuracy']),np.std(results_rft['test_accuracy'])))\n",
    "print('10-fold Precision:',results_rft['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rft['test_precision']),np.std(results_rft['test_precision'])))\n",
    "print('10-fold Recall:',results_rft['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rft['test_recall']),np.std(results_rft['test_recall'])))\n",
    "print('10-fold f1-score:',results_rft['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_rft['test_f1_score']),np.std(results_rft['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC(random_state=42)\n",
    "\n",
    "results_svm = cross_validate(estimator=model_svm,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_svm)\n",
    "\n",
    "print('Support Vector Machine Metrics:')\n",
    "print('Fit time:',results_svm['fit_time'])\n",
    "print('Score time:',results_svm['score_time'])\n",
    "print('10-fold Accuracy:',results_svm['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_svm['test_accuracy']),np.std(results_svm['test_accuracy'])))\n",
    "print('10-fold Precision:',results_svm['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_svm['test_precision']),np.std(results_svm['test_precision'])))\n",
    "print('10-fold Recall:',results_svm['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_svm['test_recall']),np.std(results_svm['test_recall'])))\n",
    "print('10-fold f1-score:',results_svm['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_svm['test_f1_score']),np.std(results_svm['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "results_KNN = cross_validate(estimator=model_KNN,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_KNN)\n",
    "\n",
    "print('K-nearest Neighbors Metrics:')\n",
    "print('Fit time:',results_KNN['fit_time'])\n",
    "print('Score time:',results_KNN['score_time'])\n",
    "print('10-fold Accuracy:',results_KNN['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_KNN['test_accuracy']),np.std(results_KNN['test_accuracy'])))\n",
    "print('10-fold Precision:',results_KNN['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_KNN['test_precision']),np.std(results_KNN['test_precision'])))\n",
    "print('10-fold Recall:',results_KNN['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_KNN['test_recall']),np.std(results_KNN['test_recall'])))\n",
    "print('10-fold f1-score:',results_KNN['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_KNN['test_f1_score']),np.std(results_KNN['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network\n",
    "from keras import models, layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_network():\n",
    "    # network defination\n",
    "    network = models.Sequential()\n",
    "    # Add fully connected layer with a ReLU\n",
    "    network.add(layers.Dense(units=16, activation='relu', input_shape=(79,)))\n",
    "    network.add(layers.Dense(units=16, activation='relu'))\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # compile network\n",
    "    network.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return network\n",
    "\n",
    "# wrap keras model\n",
    "neural_network = KerasClassifier(build_fn=create_network,\n",
    "                                epochs=100,\n",
    "                                batch_size=10,\n",
    "                                verbose=1)\n",
    "\n",
    "results_dnn = cross_validate(estimator=neural_network,\n",
    "                          X=X,#X=features,\n",
    "                          y=y,#y=labels,\n",
    "                          cv=kfold,\n",
    "                          scoring=scoring)\n",
    "print(results_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Deep Neural Network Metrics:')\n",
    "print('Fit time:',results_dnn['fit_time'])\n",
    "print('Score time:',results_dnn['score_time'])\n",
    "print('10-fold Accuracy:',results_dnn['test_accuracy'])\n",
    "print('Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_dnn['test_accuracy']),np.std(results_dnn['test_accuracy'])))\n",
    "print('10-fold Precision:',results_dnn['test_precision'])\n",
    "print('Precision(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dnn['test_precision']),np.std(results_dnn['test_precision'])))\n",
    "print('10-fold Recall:',results_dnn['test_recall'])\n",
    "print('Recall(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dnn['test_recall']),np.std(results_dnn['test_recall'])))\n",
    "print('10-fold f1-score:',results_dnn['test_f1_score'])\n",
    "print('f1-score(Mean (Standard Deviation): %f (%f)'%(np.mean(results_dnn['test_f1_score']),np.std(results_dnn['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_lr['test_accuracy']),np.std(results_lr['test_accuracy'])))\n",
    "print('Decision Tree: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_dt['test_accuracy']),np.std(results_dt['test_accuracy'])))\n",
    "print('Random Forest: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_rf['test_accuracy']),np.std(results_rf['test_accuracy'])))\n",
    "print('Random Forest with Hyperparameters Tuning: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_rft['test_accuracy']),np.std(results_rft['test_accuracy'])))\n",
    "print('Support Vector Machine: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_svm['test_accuracy']),np.std(results_svm['test_accuracy'])))\n",
    "print('K-nearest Neighbors: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_KNN['test_accuracy']),np.std(results_KNN['test_accuracy'])))\n",
    "print('Deep Neural Network: Accuracy(Mean (Standard Deviation)): %f (%f)'%(np.mean(results_dnn['test_accuracy']),np.std(results_dnn['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
